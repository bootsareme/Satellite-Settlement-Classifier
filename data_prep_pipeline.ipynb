{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e40fe57-5559-471c-8552-e2a9070c6cad",
   "metadata": {},
   "source": [
    "# Data Preparation Pipeline\n",
    "The goal of this notebook is to process the raw rasters through a pipeline that selects, cleans, and prepares data to be ready to trained. The first step is to ensure relevant dependencies are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb62ebb8-b26d-4147-90c4-8d71d9917497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.transform import from_origin\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9486e4d5-fbcc-4d91-b073-d33ad873c660",
   "metadata": {},
   "source": [
    "The raw GeoTIFFs all have different coordinate reference systems, but GURS uses WGS 84. Therefore, we need to convert all the imagery to EPSG:4326. Furthermore, to help the model digest the imagery more easily, we need to avoid loading whole GeoTIFFs into RAM at a time. For any raw GeoTIFF, we can slice the raster into 64 quadrants to enhance surface detail. Some tiles will be mostly black. If more than 20% of the tile is black pixels, we discard it. Otherwise, we save the output into a new directory on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60bbe21-3e6e-415d-8bed-3a23fa754b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating tiles: 100%|███████████████████████████████████████████████████████████████| 600/600 [33:11<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "tif_list = glob.glob(\"HLS2-s30_rgb_raw/*_[0-9][0-9].tif\")\n",
    "counter = 0    \n",
    "\n",
    "for tif_path in tqdm(tif_list, desc=\"Generating tiles\"):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        transform, width, height = calculate_default_transform(src.crs, \"EPSG:4326\", src.width, src.height, *src.bounds)\n",
    "        profile = src.profile.copy()\n",
    "        profile.update({\"crs\": \"EPSG:4326\", \"transform\": transform, \"width\": width, \"height\": height})\n",
    "        data = np.zeros((src.count, height, width), dtype=src.dtypes[0])\n",
    "        \n",
    "        for i in range(1, src.count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(src, i),\n",
    "                destination=data[i - 1],\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=\"EPSG:4326\",\n",
    "                resampling=Resampling.nearest\n",
    "            )\n",
    "\n",
    "        # Split into 8×8 grid\n",
    "        rows, cols = 8, 8\n",
    "        h_step = height // rows\n",
    "        w_step = width // cols\n",
    "\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                quad = data[:, i * h_step:(i + 1) * h_step, j * w_step:(j + 1) * w_step]\n",
    "                black_pixels = np.all(quad == 0, axis=0)\n",
    "                \n",
    "                if black_pixels.sum() / black_pixels.size > 0.2:  # discard quadrant if >20% black\n",
    "                    continue\n",
    "\n",
    "                outfile = f\"HLS2-s30_rgb/tile{counter}.tif\"\n",
    "                counter += 1\n",
    "                quad_transform = from_origin(transform[2] + j * w_step * transform[0], transform[5] + i * h_step * transform[4], transform[0], transform[4])\n",
    "                out_profile = profile.copy()\n",
    "                out_profile.update({\"height\": quad.shape[1], \"width\": quad.shape[2], \"count\": quad.shape[0], \"dtype\": quad.dtype, \"transform\": quad_transform})\n",
    "\n",
    "                with rasterio.open(outfile, \"w\", **out_profile) as dst:\n",
    "                    dst.write(quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769be08b-9eb6-4b44-9c57-6beadb2b17af",
   "metadata": {},
   "source": [
    "## Ground Truth Determenation Methodology\n",
    "The ground truths of each tile will be extracted from the GURS 2020 raster in two main steps:\n",
    "1. Isolate the portion of GURS 2020 such that it represents the geographical area covered by any specific tile.\n",
    "2. Assign a score to each land-cover label in the GURS dataset (`urban`, `rural`, `uninhabited`), reflecting the fractional representation of the respective class within each region.\n",
    "\n",
    "### I. Extract raster window of GURS corresponding to each tile.\n",
    "Let the training tile bounds be defined as four latitude and longitude pairs representing the four corners of the bounding box (provided by `training_tile.bounds`). We can denote this as $UL, UR, LL, LR$. The objective of this step is to find the rows and columns in GURS corresponding to these bounds ($ x\\in [x_0, x_f]$, $y \\in [y_0, y_f]$). \n",
    "\n",
    "We only need two degrees of freedom ($UL, LR$) to find the full bounds. Using `rasterio`, we can read the `GURS.transform` attribute get the affine transformation:\n",
    "\n",
    "$$\n",
    "\\mathbf{T} =\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & -180 \\\\\n",
    "0  & -0 & 77.91 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Apply the inverse to get row and column bounds:\n",
    "\n",
    "$$\n",
    "\\mathbf{T}^{-1}UL = \\begin{bmatrix}\n",
    "x_0 \\\\\n",
    "y_0 \\\\\n",
    "1\n",
    "\\end{bmatrix},\n",
    "$$$$\n",
    "\\mathbf{T}^{-1}LR = \\begin{bmatrix}\n",
    "x_f \\\\\n",
    "y_f \\\\\n",
    "1\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where $y$ represents the rows and $x$ represents the columns. An additional processing step is needed to ensure $x, y \\in \\mathbb{Z}$:\n",
    "\n",
    "$$\n",
    "x_0 = ⌊\\min(x_0, x_f)⌋, \\,\\,\\,\\, x_f = ⌊\\max(x_0, x_f)⌋,\n",
    "$$$$\n",
    "y_0 = ⌊\\min(y_0, y_f)⌋, \\,\\,\\,\\, y_f = ⌊\\max(y_0, y_f)⌋.\n",
    "$$\n",
    "\n",
    "Let $GURS_{wnd} = \\text{GURS}[y_0:y_f, x_0:x_f]$ represent the slice of the $\\text{GURS}$ raster at the defined bounds. After following these steps above, we get $GURS_{wnd} \\in \\{1, 2, 127\\}^{126 \\times 148}$. This is slightly smaller than the training tile's dimensions because of difference in resolution.\n",
    "\n",
    "### II. Compute frequency of each class for every tile.\n",
    "This algorithm will get the relative weighted frequencies of each value in $GURS_{wnd}$. Define a binary mask for a value $n$:\n",
    "\n",
    "$$\n",
    "\\mathcal{M}^{(n)}(i, j) = \\begin{cases} \n",
    "      1, & GURS_{wnd}[i][j] = n \\\\\n",
    "      0 & \\text{otherwise}\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "To get the frequency of any value $n$, define\n",
    "\n",
    "$$\n",
    "\\mathcal{F}(n) = \\frac{\\sum_{i=y_0}^{y_f} \\sum_{j=x_0}^{x_f} \\mathcal{M}^{(n)}(i, j)}{126 \\times 148 = 18648}.\n",
    "$$\n",
    "\n",
    "Next, the weights of each inhabited class are set to $100/9$. This is because each GURS pixel is $100 \\times 100 = 10000 \\text{ m}^2$ whereas the tile pixels are only $30 \\times 30 = 900 \\text{ m}^2$. The ratio of the weights represents the size differences of the pixel. Uninhabited pixels do not get weighted as the population density is negligible. We use the following function to ensure normalized weighted frequencies:\n",
    "\n",
    "$$\n",
    "\\mathcal{F}_w(n) = \\frac{w_n \\mathcal{F}(n)}{\\sum_{i \\in \\{1, 2, 127\\}} w_i \\mathcal{F}(i)}.\n",
    "$$\n",
    "\n",
    "In practice, rather than looping naively, we can use a vectorized process to get the entire frequency distribution in one pass:\n",
    "\n",
    "$$\n",
    "\\vec{F}_w = \\frac{\\vec{w} \\odot \\vec{f}}{\\vec{1} (\\vec{w} \\odot \\vec{f})},\n",
    "$$\n",
    "where $\\odot$ is the Hadamard product operator, $\\vec{1} \\in \\mathbb{R}^3$ is the vector of all ones, $\\vec{w} = \\begin{bmatrix} w_1 & w_2 & w_{127} \\end{bmatrix}^\\top$, and $\\vec{f} = \\begin{bmatrix} \\mathcal{F}(1) & \\mathcal{F}(2) & \\mathcal{F}(127) \\end{bmatrix}^\\top$. Finally, the frequencies are saved as a `.csv` file representing the ground truths of each tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee0f3b0-8bf5-47b7-8e0b-9cd9abb59685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tiles: 100%|██████████████████████████████████████████████████████████| 30444/30444 [00:33<00:00, 905.44it/s]\n"
     ]
    }
   ],
   "source": [
    "label_decoder = {1: \"urban\", 2: \"rural\", 127: \"uninhabited\"}\n",
    "weights = np.array([100 / 9, 100 / 9, 1])\n",
    "rows = []\n",
    "\n",
    "with rasterio.open(\"GURS_2020.tif\") as GURS:\n",
    "    for geotiff in tqdm(sorted(glob.glob(\"HLS2-s30_rgb/tile*.tif\"), key=lambda x: int(re.search(r'tile(\\d+)\\.tif', x).group(1))), desc=\"Processing tiles\"):\n",
    "        train_index = int(geotiff.split(\"tile\")[-1].split(\".tif\")[0]) # extract train index from filename\n",
    "        with rasterio.open(geotiff) as training_tile:\n",
    "            # compute window in GURS\n",
    "            col_start, row_start = ~GURS.transform * (training_tile.bounds.left, training_tile.bounds.top)\n",
    "            col_stop, row_stop = ~GURS.transform * (training_tile.bounds.right, training_tile.bounds.bottom)\n",
    "            row_start, row_stop = int(min(row_start, row_stop)), int(max(row_start, row_stop))\n",
    "            col_start, col_stop = int(min(col_start, col_stop)), int(max(col_start, col_stop))\n",
    "            GURS_wnd = GURS.read(1, window=((row_start, row_stop), (col_start, col_stop))) \n",
    "\n",
    "            # SHORTCUT: if all values are the same\n",
    "            if np.min(GURS_wnd) == np.max(GURS_wnd): \n",
    "                frequencies = np.zeros(3)\n",
    "                label = np.min(GURS_wnd)\n",
    "                frequencies[list(label_decoder.keys()).index(label)] = 1\n",
    "            else: \n",
    "                # compute score based on weighted frequency\n",
    "                freqs = np.array([(GURS_wnd == n).sum() for n in [1, 2, 127]], dtype=float)\n",
    "                freqs *= weights\n",
    "                frequencies = freqs / freqs.sum()\n",
    "                    \n",
    "            rows.append({label_decoder[n]: freq for n, freq in zip([1, 2, 127], frequencies)})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"ground_truths.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.5 (DS 3001)",
   "language": "python",
   "name": "ds3001"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
